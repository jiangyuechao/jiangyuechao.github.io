<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="爬虫-Scrapy, 且听风吟">
    <meta name="description" content="welcome to my word">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>爬虫-Scrapy | 且听风吟</title>
    <link rel="icon" type="image/x-icon, image/vnd.microsoft.icon" href="/source/images/favicon.ico">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 6.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">且听风吟</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a target="_blank" rel="noopener" href="http://jyc0507.top/#articles" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>主页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">且听风吟</div>
        <div class="logo-desc">
            
            welcome to my word
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a target="_blank" rel="noopener" href="http://jyc0507.top/#articles" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			主页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			分类
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/22.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">爬虫-Scrapy</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E7%88%AC%E8%99%AB-Scrapy/">
                                <span class="chip bg-color">爬虫-Scrapy</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Scrapy/" class="post-category">
                                Scrapy
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-10-09
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    39 分
                </div>
                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <span id="more"></span>






<p><strong>Scrapy</strong></p>
<h3 id="一-介绍"><a href="#一-介绍" class="headerlink" title="一 介绍"></a>一 介绍</h3><p>Scrapy一个开源和协作的框架，其最初是为了页面抓取 (更确切来说, 网络抓取 )所设计的，使用它可以以快速、简单、可扩展的方式从网站中提取所需的数据。但目前Scrapy的用途十分广泛，可用于如数据挖掘、监测和自动化测试等领域，也可以应用在获取API所返回的数据(例如 Amazon Associates Web Services ) 或者通用的网络爬虫。</p>
<p>Scrapy 是基于twisted框架开发而来，twisted是一个流行的事件驱动的python网络框架。因此Scrapy使用了一种非阻塞（又名异步）的代码来实现并发。</p>
<p><strong>The data flow in Scrapy is controlled by the execution engine, and goes like this:</strong></p>
<ol>
<li>The <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-engine">Engine</a> gets the initial Requests to crawl from the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-spiders">Spider</a>.</li>
<li>The <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-engine">Engine</a> schedules the Requests in the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-scheduler">Scheduler</a> and asks for the next Requests to crawl.</li>
<li>The <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-scheduler">Scheduler</a> returns the next Requests to the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-engine">Engine</a>.</li>
<li>The <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-engine">Engine</a> sends the Requests to the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-downloader">Downloader</a>, passing through the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-downloader-middleware">Downloader Middlewares</a> (see <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#scrapy.downloadermiddlewares.DownloaderMiddleware.process_request"><code>process_request()</code></a>).</li>
<li>Once the page finishes downloading the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-downloader">Downloader</a> generates a Response (with that page) and sends it to the Engine, passing through the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-downloader-middleware">Downloader Middlewares</a> (see <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#scrapy.downloadermiddlewares.DownloaderMiddleware.process_response"><code>process_response()</code></a>).</li>
<li>The <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-engine">Engine</a> receives the Response from the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-downloader">Downloader</a> and sends it to the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-spiders">Spider</a> for processing, passing through the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-spider-middleware">Spider Middleware</a> (see <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/spider-middleware.html#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_input"><code>process_spider_input()</code></a>).</li>
<li>The <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-spiders">Spider</a> processes the Response and returns scraped items and new Requests (to follow) to the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-engine">Engine</a>, passing through the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-spider-middleware">Spider Middleware</a> (see <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/spider-middleware.html#scrapy.spidermiddlewares.SpiderMiddleware.process_spider_output"><code>process_spider_output()</code></a>).</li>
<li>The <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-engine">Engine</a> sends processed items to <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-pipelines">Item Pipelines</a>, then send processed Requests to the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-scheduler">Scheduler</a> and asks for possible next Requests to crawl.</li>
<li>The process repeats (from step 1) until there are no more requests from the <a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html#component-scheduler">Scheduler</a>.</li>
</ol>
<p><strong>Components：</strong></p>
<ol>
<li><p>引擎(EGINE)</p>
<p>引擎负责控制系统所有组件之间的数据流，并在某些动作发生时触发事件。有关详细信息，请参见上面的数据流部分。</p>
</li>
<li><p><strong>调度器(SCHEDULER)</strong><br>用来接受引擎发过来的请求, 压入队列中, 并在引擎再次请求的时候返回. 可以想像成一个URL的优先级队列, 由它来决定下一个要抓取的网址是什么, 同时去除重复的网址</p>
</li>
<li><p><strong>下载器(DOWLOADER)</strong><br>用于下载网页内容, 并将网页内容返回给EGINE，下载器是建立在twisted这个高效的异步模型上的</p>
</li>
<li><p><strong>爬虫(SPIDERS)</strong><br>SPIDERS是开发人员自定义的类，用来解析responses，并且提取items，或者发送新的请求</p>
</li>
<li><p><strong>项目管道(ITEM PIPLINES)</strong><br>在items被提取后负责处理它们，主要包括清理、验证、持久化（比如存到数据库）等操作</p>
</li>
<li><p>下载器中间件(Downloader Middlewares)</p>
<p>位于Scrapy引擎和下载器之间，主要用来处理从EGINE传到DOWLOADER的请求request，已经从DOWNLOADER传到EGINE的响应response，你可用该中间件做以下几件事</p>
<ol>
<li>process a request just before it is sent to the Downloader (i.e. right before Scrapy sends the request to the website);</li>
<li>change received response before passing it to a spider;</li>
<li>send a new Request instead of passing received response to a spider;</li>
<li>pass response to a spider without fetching a web page;</li>
<li>silently drop some requests.</li>
</ol>
</li>
<li><p><strong>爬虫中间件(Spider Middlewares)</strong><br>位于EGINE和SPIDERS之间，主要工作是处理SPIDERS的输入（即responses）和输出（即requests）</p>
</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/architecture.html">官网链接：https://docs.scrapy.org/en/latest/topics/architecture.html</a></p>
<h3 id="二-安装"><a href="#二-安装" class="headerlink" title="二 安装"></a>二 安装</h3><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#Windows平台</span>
    <span class="token number">1</span>、pip3 install wheel <span class="token comment">#安装后，便支持通过wheel文件安装软件，wheel文件官网：https://www.lfd.uci.edu/~gohlke/pythonlibs</span>
    <span class="token number">3</span>、pip3 install lxml
    <span class="token number">4</span>、pip3 install pyopenssl
    <span class="token number">5</span>、下载并安装pywin32：https<span class="token punctuation">:</span><span class="token operator">//</span>sourceforge<span class="token punctuation">.</span>net<span class="token operator">/</span>projects<span class="token operator">/</span>pywin32<span class="token operator">/</span>files<span class="token operator">/</span>pywin32<span class="token operator">/</span>
    <span class="token number">6</span>、下载twisted的wheel文件：http<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>lfd<span class="token punctuation">.</span>uci<span class="token punctuation">.</span>edu<span class="token operator">/</span><span class="token operator">~</span>gohlke<span class="token operator">/</span>pythonlibs<span class="token operator">/</span><span class="token comment">#twisted</span>
    <span class="token number">7</span>、执行pip3 install 下载目录\Twisted<span class="token operator">-</span><span class="token number">17.9</span><span class="token number">.0</span><span class="token operator">-</span>cp36<span class="token operator">-</span>cp36m<span class="token operator">-</span>win_amd64<span class="token punctuation">.</span>whl
    <span class="token number">8</span>、pip3 install scrapy

<span class="token comment">#Linux平台</span>
    <span class="token number">1</span>、pip3 install scrapy</code></pre>

<h3 id="三-命令行工具"><a href="#三-命令行工具" class="headerlink" title="三 命令行工具"></a>三 命令行工具</h3><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#1 查看帮助</span>
    scrapy <span class="token operator">-</span>h
    scrapy <span class="token operator">&lt;</span>command<span class="token operator">&gt;</span> <span class="token operator">-</span>h

<span class="token comment">#2 有两种命令：其中Project-only必须切到项目文件夹下才能执行，而Global的命令则不需要</span>
    Global commands<span class="token punctuation">:</span>
        startproject <span class="token comment">#创建项目</span>
        genspider    <span class="token comment">#创建爬虫程序</span>
        settings     <span class="token comment">#如果是在项目目录下，则得到的是该项目的配置</span>
        runspider    <span class="token comment">#运行一个独立的python文件，不必创建项目</span>
        shell        <span class="token comment">#scrapy shell url地址  在交互式调试，如选择器规则正确与否</span>
        fetch        <span class="token comment">#独立于程单纯地爬取一个页面，可以拿到请求头</span>
        view         <span class="token comment">#下载完毕后直接弹出浏览器，以此可以分辨出哪些数据是ajax请求</span>
        version      <span class="token comment">#scrapy version 查看scrapy的版本，scrapy version -v查看scrapy依赖库的版本</span>
    Project<span class="token operator">-</span>only commands<span class="token punctuation">:</span>
        crawl        <span class="token comment">#运行爬虫，必须创建项目才行，确保配置文件中ROBOTSTXT_OBEY = False</span>
        check        <span class="token comment">#检测项目中有无语法错误</span>
        <span class="token builtin">list</span>         <span class="token comment">#列出项目中所包含的爬虫名</span>
        edit         <span class="token comment">#编辑器，一般不用</span>
        parse        <span class="token comment">#scrapy parse url地址 --callback 回调函数  #以此可以验证我们的回调函数是否正确</span>
        bench        <span class="token comment">#scrapy bentch压力测试</span>

<span class="token comment">#3 官网链接</span>
    https<span class="token punctuation">:</span><span class="token operator">//</span>docs<span class="token punctuation">.</span>scrapy<span class="token punctuation">.</span>org<span class="token operator">/</span>en<span class="token operator">/</span>latest<span class="token operator">/</span>topics<span class="token operator">/</span>commands<span class="token punctuation">.</span>html
<span class="token comment">#1、执行全局命令：请确保不在某个项目的目录下，排除受该项目配置的影响</span>
scrapy startproject MyProject

cd MyProject
scrapy genspider baidu www<span class="token punctuation">.</span>baidu<span class="token punctuation">.</span>com

scrapy settings <span class="token operator">-</span><span class="token operator">-</span>get XXX <span class="token comment">#如果切换到项目目录下，看到的则是该项目的配置</span>

scrapy runspider baidu<span class="token punctuation">.</span>py

scrapy shell https<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>baidu<span class="token punctuation">.</span>com
    response
    response<span class="token punctuation">.</span>status
    response<span class="token punctuation">.</span>body
    view<span class="token punctuation">(</span>response<span class="token punctuation">)</span>
    
scrapy view https<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>taobao<span class="token punctuation">.</span>com <span class="token comment">#如果页面显示内容不全，不全的内容则是ajax请求实现的，以此快速定位问题</span>

scrapy fetch <span class="token operator">-</span><span class="token operator">-</span>nolog <span class="token operator">-</span><span class="token operator">-</span>headers https<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>taobao<span class="token punctuation">.</span>com

scrapy version <span class="token comment">#scrapy的版本</span>

scrapy version <span class="token operator">-</span>v <span class="token comment">#依赖库的版本</span>

<span class="token comment">#2、执行项目命令：切到项目目录下</span>
scrapy crawl baidu
scrapy check
scrapy <span class="token builtin">list</span>
scrapy parse http<span class="token punctuation">:</span><span class="token operator">//</span>quotes<span class="token punctuation">.</span>toscrape<span class="token punctuation">.</span>com<span class="token operator">/</span> <span class="token operator">-</span><span class="token operator">-</span>callback parse
scrapy bench
    </code></pre>

<h3 id="四-项目结构以及爬虫应用简介"><a href="#四-项目结构以及爬虫应用简介" class="headerlink" title="四 项目结构以及爬虫应用简介"></a>四 项目结构以及爬虫应用简介</h3><pre class="language-python" data-language="python"><code class="language-python">project_name<span class="token operator">/</span>
   scrapy<span class="token punctuation">.</span>cfg
   project_name<span class="token operator">/</span>
       __init__<span class="token punctuation">.</span>py
       items<span class="token punctuation">.</span>py
       pipelines<span class="token punctuation">.</span>py
       settings<span class="token punctuation">.</span>py
       spiders<span class="token operator">/</span>
           __init__<span class="token punctuation">.</span>py
           爬虫<span class="token number">1</span><span class="token punctuation">.</span>py
           爬虫<span class="token number">2</span><span class="token punctuation">.</span>py
           爬虫<span class="token number">3</span><span class="token punctuation">.</span>py</code></pre>

<p>文件说明：</p>
<ul>
<li>scrapy.cfg 项目的主配置信息，用来部署scrapy时使用，爬虫相关的配置信息在settings.py文件中。</li>
<li>items.py 设置数据存储模板，用于结构化数据，如：Django的Model</li>
<li>pipelines 数据处理行为，如：一般结构化的数据持久化</li>
<li>settings.py 配置文件，如：递归的层数、并发数，延迟下载等。*<em>强调:配置文件的选项必须大写否则视为无效*</em>*<em>，正确写法USER_AGENT=’xxxx’</em>*</li>
<li>spiders 爬虫目录，如：创建文件，编写爬虫规则</li>
</ul>
<p><em>注意：一般创建爬虫文件时，以网站域名命名</em></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#在项目目录下新建：entrypoint.py</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>cmdline <span class="token keyword">import</span> execute
execute<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'scrapy'</span><span class="token punctuation">,</span> <span class="token string">'crawl'</span><span class="token punctuation">,</span> <span class="token string">'xiaohua'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> sys<span class="token punctuation">,</span>os
sys<span class="token punctuation">.</span>stdout<span class="token operator">=</span>io<span class="token punctuation">.</span>TextIOWrapper<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span><span class="token builtin">buffer</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'gb18030'</span><span class="token punctuation">)</span></code></pre>

<h3 id="五-Spiders"><a href="#五-Spiders" class="headerlink" title="五 Spiders"></a>五 Spiders</h3><p><strong>1、介绍</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#1、Spiders是由一系列类（定义了一个网址或一组网址将被爬取）组成，具体包括如何执行爬取任务并且如何从页面中提取结构化的数据。</span>

<span class="token comment">#2、换句话说，Spiders是你为了一个特定的网址或一组网址自定义爬取和解析页面行为的地方</span></code></pre>

<p><strong>2、Spiders会循环做如下事情</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#1、生成初始的Requests来爬取第一个URLS，并且标识一个回调函数</span>
第一个请求定义在start_requests<span class="token punctuation">(</span><span class="token punctuation">)</span>方法内默认从start_urls列表中获得url地址来生成Request请求，默认的回调函数是parse方法。回调函数在下载完成返回response时自动触发

<span class="token comment">#2、在回调函数中，解析response并且返回值</span>
返回值可以<span class="token number">4</span>种：
        包含解析数据的字典
        Item对象
        新的Request对象（新的Requests也需要指定一个回调函数）
        或者是可迭代对象（包含Items或Request）

<span class="token comment">#3、在回调函数中解析页面内容</span>
通常使用Scrapy自带的Selectors，但很明显你也可以使用Beutifulsoup，lxml或其他你爱用啥用啥。

<span class="token comment">#4、最后，针对返回的Items对象将会被持久化到数据库</span>
通过Item Pipeline组件存到数据库：https<span class="token punctuation">:</span><span class="token operator">//</span>docs<span class="token punctuation">.</span>scrapy<span class="token punctuation">.</span>org<span class="token operator">/</span>en<span class="token operator">/</span>latest<span class="token operator">/</span>topics<span class="token operator">/</span>item<span class="token operator">-</span>pipeline<span class="token punctuation">.</span>html<span class="token comment">#topics-item-pipeline）</span>
或者导出到不同的文件（通过Feed exports：https<span class="token punctuation">:</span><span class="token operator">//</span>docs<span class="token punctuation">.</span>scrapy<span class="token punctuation">.</span>org<span class="token operator">/</span>en<span class="token operator">/</span>latest<span class="token operator">/</span>topics<span class="token operator">/</span>feed<span class="token operator">-</span>exports<span class="token punctuation">.</span>html<span class="token comment">#topics-feed-exports）</span></code></pre>

<p><strong>3、Spiders总共提供了五种类：</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#1、scrapy.spiders.Spider #scrapy.Spider等同于scrapy.spiders.Spider</span>
<span class="token comment">#2、scrapy.spiders.CrawlSpider</span>
<span class="token comment">#3、scrapy.spiders.XMLFeedSpider</span>
<span class="token comment">#4、scrapy.spiders.CSVFeedSpider</span>
<span class="token comment">#5、scrapy.spiders.SitemapSpider</span></code></pre>

<p><strong>4、导入使用</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> Spider<span class="token punctuation">,</span>CrawlSpider<span class="token punctuation">,</span>XMLFeedSpider<span class="token punctuation">,</span>CSVFeedSpider<span class="token punctuation">,</span>SitemapSpider

<span class="token keyword">class</span> <span class="token class-name">AmazonSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#自定义类，继承Spiders提供的基类</span>
    name <span class="token operator">=</span> <span class="token string">'amazon'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'www.amazon.cn'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.amazon.cn/'</span><span class="token punctuation">]</span>
    

```
<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">pass</span></code></pre>

<p><strong>5、class scrapy.spiders.Spider</strong></p>
<p>这是最简单的spider类，任何其他的spider类都需要继承它（包含你自己定义的）。</p>
<p>该类不提供任何特殊的功能，它仅提供了一个默认的start_requests方法默认从start_urls中读取url地址发送requests请求，并且默认parse作为回调函数</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">AmazonSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'amazon'</span> 

```
allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'www.amazon.cn'</span><span class="token punctuation">]</span> 

start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.amazon.cn/'</span><span class="token punctuation">]</span>

custom_settings <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'BOT_NAME'</span> <span class="token punctuation">:</span> <span class="token string">'Egon_Spider_Amazon'</span><span class="token punctuation">,</span>
    <span class="token string">'REQUEST_HEADERS'</span> <span class="token punctuation">:</span> <span class="token punctuation">{</span>
      <span class="token string">'Accept'</span><span class="token punctuation">:</span> <span class="token string">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class="token punctuation">,</span>
      <span class="token string">'Accept-Language'</span><span class="token punctuation">:</span> <span class="token string">'en'</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">pass</span>
<span class="token comment">#1、name = 'amazon' </span>
定义爬虫名，scrapy会根据该值定位爬虫程序
所以它必须要有且必须唯一（In Python <span class="token number">2</span> this must be ASCII only<span class="token punctuation">.</span>）

<span class="token comment">#2、allowed_domains = ['www.amazon.cn'] </span>
定义允许爬取的域名，如果OffsiteMiddleware启动（默认就启动），
那么不属于该列表的域名及其子域名都不允许爬取
如果爬取的网址为：https<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>example<span class="token punctuation">.</span>com<span class="token operator">/</span><span class="token number">1</span><span class="token punctuation">.</span>html，那就添加<span class="token string">'example.com'</span>到列表<span class="token punctuation">.</span>

<span class="token comment">#3、start_urls = ['http://www.amazon.cn/']</span>
如果没有指定url，就从该列表中读取url来生成第一个请求

<span class="token comment">#4、custom_settings</span>
值为一个字典，定义一些配置信息，在运行爬虫程序时，这些配置会覆盖项目级别的配置
所以custom_settings必须被定义成一个类属性，由于settings会在类实例化前被加载

<span class="token comment">#5、settings</span>
通过self<span class="token punctuation">.</span>settings<span class="token punctuation">[</span><span class="token string">'配置项的名字'</span><span class="token punctuation">]</span>可以访问settings<span class="token punctuation">.</span>py中的配置，如果自己定义了custom_settings还是以自己的为准

<span class="token comment">#6、logger</span>
日志名默认为spider的名字
self<span class="token punctuation">.</span>logger<span class="token punctuation">.</span>debug<span class="token punctuation">(</span><span class="token string">'=============&gt;%s'</span> <span class="token operator">%</span>self<span class="token punctuation">.</span>settings<span class="token punctuation">[</span><span class="token string">'BOT_NAME'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment">#5、crawler：了解</span>
该属性必须被定义到类方法from_crawler中

<span class="token comment">#6、from_crawler(crawler, *args, **kwargs)：了解</span>
You probably won’t need to override this directly  because the default implementation acts <span class="token keyword">as</span> a proxy to the __init__<span class="token punctuation">(</span><span class="token punctuation">)</span> method<span class="token punctuation">,</span> calling it <span class="token keyword">with</span> the given arguments args <span class="token keyword">and</span> named arguments kwargs<span class="token punctuation">.</span>

<span class="token comment">#7、start_requests()</span>
该方法用来发起第一个Requests请求，且必须返回一个可迭代的对象。它在爬虫程序打开时就被Scrapy调用，Scrapy只调用它一次。
默认从start_urls里取出每个url来生成Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> dont_filter<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">#针对参数dont_filter,请看自定义去重规则</span>

如果你想要改变起始爬取的Requests，你就需要覆盖这个方法，例如你想要起始发送一个POST请求，如下
<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'myspider'</span>

```
<span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>scrapy<span class="token punctuation">.</span>FormRequest<span class="token punctuation">(</span><span class="token string">"http://www.example.com/login"</span><span class="token punctuation">,</span>
                               formdata<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'user'</span><span class="token punctuation">:</span> <span class="token string">'john'</span><span class="token punctuation">,</span> <span class="token string">'pass'</span><span class="token punctuation">:</span> <span class="token string">'secret'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                               callback<span class="token operator">=</span>self<span class="token punctuation">.</span>logged_in<span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">logged_in</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># here you would extract links to follow and return Requests for</span>
    <span class="token comment"># each of them, with another callback</span>
    <span class="token keyword">pass</span>
```

<span class="token comment">#8、parse(response)</span>
这是默认的回调函数，所有的回调函数必须返回an iterable of Request <span class="token keyword">and</span><span class="token operator">/</span><span class="token keyword">or</span> dicts <span class="token keyword">or</span> Item objects<span class="token punctuation">.</span>

<span class="token comment">#9、log(message[, level, component])：了解</span>
Wrapper that sends a log message through the Spider’s logger<span class="token punctuation">,</span> kept <span class="token keyword">for</span> backwards compatibility<span class="token punctuation">.</span> For more information see Logging <span class="token keyword">from</span> Spiders<span class="token punctuation">.</span>

<span class="token comment">#10、closed(reason)</span>
爬虫程序结束时自动触发
去重规则应该多个爬虫共享的，但凡一个爬虫爬取了，其他都不要爬了，实现方式如下

<span class="token comment">#方法一：</span>
<span class="token number">1</span>、新增类属性
visited<span class="token operator">=</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#类属性</span>

<span class="token number">2</span>、回调函数parse方法内：
<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> response<span class="token punctuation">.</span>url <span class="token keyword">in</span> self<span class="token punctuation">.</span>visited<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

```
self<span class="token punctuation">.</span>visited<span class="token punctuation">.</span>add<span class="token punctuation">(</span>response<span class="token punctuation">.</span>url<span class="token punctuation">)</span> 
```

<span class="token comment">#方法一改进：针对url可能过长，所以我们存放url的hash值</span>
<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        url<span class="token operator">=</span>md5<span class="token punctuation">(</span>response<span class="token punctuation">.</span>request<span class="token punctuation">.</span>url<span class="token punctuation">)</span>
    <span class="token keyword">if</span> url <span class="token keyword">in</span> self<span class="token punctuation">.</span>visited<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

```
self<span class="token punctuation">.</span>visited<span class="token punctuation">.</span>add<span class="token punctuation">(</span>url<span class="token punctuation">)</span> 
```

<span class="token comment">#方法二：Scrapy自带去重功能</span>
配置文件：
DUPEFILTER_CLASS <span class="token operator">=</span> <span class="token string">'scrapy.dupefilter.RFPDupeFilter'</span> <span class="token comment">#默认的去重规则帮我们去重，去重规则在内存中</span>
DUPEFILTER_DEBUG <span class="token operator">=</span> <span class="token boolean">False</span>
JOBDIR <span class="token operator">=</span> <span class="token string">"保存范文记录的日志路径，如：/root/"</span>  <span class="token comment"># 最终路径为 /root/requests.seen，去重规则放文件中</span>

scrapy自带去重规则默认为RFPDupeFilter，只需要我们指定
Request<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span>dont_filter<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> ，如果dont_filter<span class="token operator">=</span><span class="token boolean">True</span>则告诉Scrapy这个URL不参与去重。

<span class="token comment">#方法三：</span>
我们也可以仿照RFPDupeFilter自定义去重规则，

<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>dupefilter <span class="token keyword">import</span> RFPDupeFilter，看源码，仿照BaseDupeFilter

<span class="token comment">#步骤一：在项目目录下自定义去重文件dup.py</span>
<span class="token keyword">class</span> <span class="token class-name">UrlFilter</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>visited <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#或者放到数据库</span>

    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_settings</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> settings<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> cls<span class="token punctuation">(</span><span class="token punctuation">)</span>

```
<span class="token keyword">def</span> <span class="token function">request_seen</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> request<span class="token punctuation">.</span>url <span class="token keyword">in</span> self<span class="token punctuation">.</span>visited<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token boolean">True</span>
    self<span class="token punctuation">.</span>visited<span class="token punctuation">.</span>add<span class="token punctuation">(</span>request<span class="token punctuation">.</span>url<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">open</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># can return deferred</span>
    <span class="token keyword">pass</span>

<span class="token keyword">def</span> <span class="token function">close</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> reason<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># can return a deferred</span>
    <span class="token keyword">pass</span>

<span class="token keyword">def</span> <span class="token function">log</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># log that a request has been filtered</span>
    <span class="token keyword">pass</span>
```

<span class="token comment">#步骤二：配置文件settings.py：</span>
DUPEFILTER_CLASS <span class="token operator">=</span> <span class="token string">'项目名.dup.UrlFilter'</span>

<span class="token comment"># 源码分析：</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>core<span class="token punctuation">.</span>scheduler <span class="token keyword">import</span> Scheduler
见Scheduler下的enqueue_request方法：self<span class="token punctuation">.</span>df<span class="token punctuation">.</span>request_seen<span class="token punctuation">(</span>request<span class="token punctuation">)</span>
<span class="token comment">#例一：</span>
<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'example.com'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'example.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string">'http://www.example.com/1.html'</span><span class="token punctuation">,</span>
        <span class="token string">'http://www.example.com/2.html'</span><span class="token punctuation">,</span>
        <span class="token string">'http://www.example.com/3.html'</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

```
<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'A response from %s just arrived!'</span><span class="token punctuation">,</span> response<span class="token punctuation">.</span>url<span class="token punctuation">)</span>
```

    
<span class="token comment">#例二：一个回调函数返回多个Requests和Items</span>
<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'example.com'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'example.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string">'http://www.example.com/1.html'</span><span class="token punctuation">,</span>
        <span class="token string">'http://www.example.com/2.html'</span><span class="token punctuation">,</span>
        <span class="token string">'http://www.example.com/3.html'</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

```
<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> h3 <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//h3'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> <span class="token punctuation">{</span><span class="token string">"title"</span><span class="token punctuation">:</span> h3<span class="token punctuation">}</span>

    <span class="token keyword">for</span> url <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
```

            
<span class="token comment">#例三：在start_requests()内直接指定起始爬取的urls，start_urls就没有用了，</span>

<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> myproject<span class="token punctuation">.</span>items <span class="token keyword">import</span> MyItem

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'example.com'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'example.com'</span><span class="token punctuation">]</span>

```
<span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span><span class="token string">'http://www.example.com/1.html'</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
    <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span><span class="token string">'http://www.example.com/2.html'</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
    <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span><span class="token string">'http://www.example.com/3.html'</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> h3 <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//h3'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> MyItem<span class="token punctuation">(</span>title<span class="token operator">=</span>h3<span class="token punctuation">)</span>

    <span class="token keyword">for</span> url <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
我们可能需要在命令行为爬虫程序传递参数，比如传递初始的url，像这样
<span class="token comment">#命令行执行</span>
scrapy crawl myspider <span class="token operator">-</span>a category<span class="token operator">=</span>electronics

<span class="token comment">#在__init__方法中可以接收外部传进来的参数</span>
<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'myspider'</span>

```
<span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> category<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token builtin">super</span><span class="token punctuation">(</span>MySpider<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.example.com/categories/%s'</span> <span class="token operator">%</span> category<span class="token punctuation">]</span>
    <span class="token comment">#...</span>

```

        
<span class="token comment">#注意接收的参数全都是字符串，如果想要结构化的数据，你需要用类似json.loads的方法</span></code></pre>

<p><strong>6、<a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/spiders.html#generic-spiders">其他通用Spiders：https://docs.scrapy.org/en/latest/topics/spiders.html#generic-spiders</a></strong></p>
<h3 id="六-Selectors"><a href="#六-Selectors" class="headerlink" title="六 Selectors"></a>六 Selectors</h3><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#1 //与/</span>
<span class="token comment">#2 text</span>
<span class="token comment">#3、extract与extract_first:从selector对象中解出内容</span>
<span class="token comment">#4、属性：xpath的属性加前缀@</span>
<span class="token comment">#4、嵌套查找</span>
<span class="token comment">#5、设置默认值</span>
<span class="token comment">#4、按照属性查找</span>
<span class="token comment">#5、按照属性模糊查找</span>
<span class="token comment">#6、正则表达式</span>
<span class="token comment">#7、xpath相对路径</span>
<span class="token comment">#8、带变量的xpath</span>
response<span class="token punctuation">.</span>selector<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token punctuation">)</span>
response<span class="token punctuation">.</span>selector<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token punctuation">)</span>
可简写为
response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token punctuation">)</span>
response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#1 //与/</span>
response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//body/a/'</span><span class="token punctuation">)</span><span class="token comment">#</span>
response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'div a::text'</span><span class="token punctuation">)</span>

<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//body/a'</span><span class="token punctuation">)</span> <span class="token comment">#开头的//代表从整篇文档中寻找,body之后的/代表body的儿子</span>
<span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//body//a'</span><span class="token punctuation">)</span> <span class="token comment">#开头的//代表从整篇文档中寻找,body之后的//代表body的子子孙孙</span>
<span class="token punctuation">[</span><span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">'//body//a'</span> data<span class="token operator">=</span><span class="token string">'&lt;a href="image1.html"&gt;Name: My image 1 &lt;'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">'//body//a'</span> data<span class="token operator">=</span><span class="token string">'&lt;a href="image2.html"&gt;Name: My image 2 &lt;'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">'//body//a'</span> data<span class="token operator">=</span>'<span class="token operator">&lt;</span>a href<span class="token operator">=</span>"
image3<span class="token punctuation">.</span>html<span class="token string">"&gt;Name: My image 3 &lt;'&gt;, &lt;Selector xpath='//body//a' data='&lt;a href="</span>image4<span class="token punctuation">.</span>html<span class="token string">"&gt;Name: My image 4 &lt;'&gt;, &lt;Selector xpath='//body//a' data='&lt;a href="</span>image5<span class="token punctuation">.</span>html"<span class="token operator">&gt;</span>Name<span class="token punctuation">:</span> My image <span class="token number">5</span> <span class="token operator">&lt;</span>'<span class="token operator">&gt;</span><span class="token punctuation">]</span>

<span class="token comment">#2 text</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//body//a/text()'</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'body a::text'</span><span class="token punctuation">)</span>

<span class="token comment">#3、extract与extract_first:从selector对象中解出内容</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div/a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'Name: My image 1 '</span><span class="token punctuation">,</span> <span class="token string">'Name: My image 2 '</span><span class="token punctuation">,</span> <span class="token string">'Name: My image 3 '</span><span class="token punctuation">,</span> <span class="token string">'Name: My image 4 '</span><span class="token punctuation">,</span> <span class="token string">'Name: My image 5 '</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'div a::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'Name: My image 1 '</span><span class="token punctuation">,</span> <span class="token string">'Name: My image 2 '</span><span class="token punctuation">,</span> <span class="token string">'Name: My image 3 '</span><span class="token punctuation">,</span> <span class="token string">'Name: My image 4 '</span><span class="token punctuation">,</span> <span class="token string">'Name: My image 5 '</span><span class="token punctuation">]</span>

<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div/a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token string">'Name: My image 1 '</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'div a::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token string">'Name: My image 1 '</span>

<span class="token comment">#4、属性：xpath的属性加前缀@</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div/a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token string">'image1.html'</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'div a::attr(href)'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token string">'image1.html'</span>

<span class="token comment">#4、嵌套查找</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token string">'image1.html'</span>

<span class="token comment">#5、设置默认值</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@id="xxx"]'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span>default<span class="token operator">=</span><span class="token string">"not found"</span><span class="token punctuation">)</span>
<span class="token string">'not found'</span>

<span class="token comment">#4、按照属性查找</span>
response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@id="images"]/a[@href="image3.html"]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'#images a[@href="image3.html"]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#5、按照属性模糊查找</span>
response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//a[contains(@href,"image")]/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'a[href*="image"]::attr(href)'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//a[contains(@href,"image")]/img/@src'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'a[href*="imag"] img::attr(src)'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@href="image1.html"]'</span><span class="token punctuation">)</span>
response<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'*[href="image1.html"]'</span><span class="token punctuation">)</span>

<span class="token comment">#6、正则表达式</span>
response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>re<span class="token punctuation">(</span><span class="token string">r'Name: (.*)'</span><span class="token punctuation">)</span>
response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>re_first<span class="token punctuation">(</span><span class="token string">r'Name: (.*)'</span><span class="token punctuation">)</span>

<span class="token comment">#7、xpath相对路径</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> res<span class="token operator">=</span>response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//a[contains(@href,"3")]'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> res<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'img'</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">'img'</span> data<span class="token operator">=</span><span class="token string">'&lt;img src="image3_thumb.jpg"&gt;'</span><span class="token operator">&gt;</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> res<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./img'</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">'./img'</span> data<span class="token operator">=</span><span class="token string">'&lt;img src="image3_thumb.jpg"&gt;'</span><span class="token operator">&gt;</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> res<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//img'</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">'.//img'</span> data<span class="token operator">=</span><span class="token string">'&lt;img src="image3_thumb.jpg"&gt;'</span><span class="token operator">&gt;</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> res<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//img'</span><span class="token punctuation">)</span> <span class="token comment">#这就是从头开始扫描</span>
<span class="token punctuation">[</span><span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">'//img'</span> data<span class="token operator">=</span><span class="token string">'&lt;img src="image1_thumb.jpg"&gt;'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">'//img'</span> data<span class="token operator">=</span><span class="token string">'&lt;img src="image2_thumb.jpg"&gt;'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">'//img'</span> data<span class="token operator">=</span><span class="token string">'&lt;img src="image3_thumb.jpg"&gt;'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>Selector xpa
th<span class="token operator">=</span><span class="token string">'//img'</span> data<span class="token operator">=</span><span class="token string">'&lt;img src="image4_thumb.jpg"&gt;'</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> <span class="token operator">&lt;</span>Selector xpath<span class="token operator">=</span><span class="token string">'//img'</span> data<span class="token operator">=</span><span class="token string">'&lt;img src="image5_thumb.jpg"&gt;'</span><span class="token operator">&gt;</span><span class="token punctuation">]</span>

<span class="token comment">#8、带变量的xpath</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@id=$xxx]/a/text()'</span><span class="token punctuation">,</span>xxx<span class="token operator">=</span><span class="token string">'images'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token string">'Name: My image 1 '</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[count(a)=$yyy]/@id'</span><span class="token punctuation">,</span>yyy<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#求有5个a标签的div的id</span>
<span class="token string">'images'</span></code></pre>

<p><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/selectors.html">https://docs.scrapy.org/en/latest/topics/selectors.html</a></p>
<h3 id="七-Items"><a href="#七-Items" class="headerlink" title="七 Items"></a>七 Items</h3><p><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/items.html">https://docs.scrapy.org/en/latest/topics/items.html</a></p>
<h3 id="八-Item-Pipeline"><a href="#八-Item-Pipeline" class="headerlink" title="八 Item Pipeline"></a>八 Item Pipeline</h3><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#一：可以写多个Pipeline类</span>
<span class="token comment">#1、如果优先级高的Pipeline的process_item返回一个值或者None，会自动传给下一个pipline的process_item,</span>
<span class="token comment">#2、如果只想让第一个Pipeline执行，那得让第一个pipline的process_item抛出异常raise DropItem()</span>

<span class="token comment">#3、可以用spider.name == '爬虫名' 来控制哪些爬虫用哪些pipeline</span>

二：示范
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exceptions <span class="token keyword">import</span> DropItem

<span class="token keyword">class</span> <span class="token class-name">CustomPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>v<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>value <span class="token operator">=</span> v

```
<span class="token decorator annotation punctuation">@classmethod</span>
<span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Scrapy会先通过getattr判断我们是否自定义了from_crawler,有则调它来完
    成实例化
    """</span>
    val <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>getint<span class="token punctuation">(</span><span class="token string">'MMMM'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> cls<span class="token punctuation">(</span>val<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    爬虫刚启动时执行一次
    """</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'000000'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    爬虫关闭时执行一次
    """</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'111111'</span><span class="token punctuation">)</span>

```

```
<span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 操作并进行持久化</span>

    <span class="token comment"># return表示会被后续的pipeline继续处理</span>
    <span class="token keyword">return</span> item

    <span class="token comment"># 表示将item丢弃，不会被后续pipeline处理</span>
    <span class="token comment"># raise DropItem()</span>
<span class="token comment">#1、settings.py</span>
HOST<span class="token operator">=</span><span class="token string">"127.0.0.1"</span>
PORT<span class="token operator">=</span><span class="token number">27017</span>
USER<span class="token operator">=</span><span class="token string">"root"</span>
PWD<span class="token operator">=</span><span class="token string">"123"</span>
DB<span class="token operator">=</span><span class="token string">"amazon"</span>
TABLE<span class="token operator">=</span><span class="token string">"goods"</span>



ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">'Amazon.pipelines.CustomPipeline'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

<span class="token comment">#2、pipelines.py</span>
<span class="token keyword">class</span> <span class="token class-name">CustomPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>host<span class="token punctuation">,</span>port<span class="token punctuation">,</span>user<span class="token punctuation">,</span>pwd<span class="token punctuation">,</span>db<span class="token punctuation">,</span>table<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>host<span class="token operator">=</span>host
        self<span class="token punctuation">.</span>port<span class="token operator">=</span>port
        self<span class="token punctuation">.</span>user<span class="token operator">=</span>user
        self<span class="token punctuation">.</span>pwd<span class="token operator">=</span>pwd
        self<span class="token punctuation">.</span>db<span class="token operator">=</span>db
        self<span class="token punctuation">.</span>table<span class="token operator">=</span>table

```
<span class="token decorator annotation punctuation">@classmethod</span>
<span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Scrapy会先通过getattr判断我们是否自定义了from_crawler,有则调它来完
    成实例化
    """</span>
    HOST <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'HOST'</span><span class="token punctuation">)</span>
    PORT <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'PORT'</span><span class="token punctuation">)</span>
    USER <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'USER'</span><span class="token punctuation">)</span>
    PWD <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'PWD'</span><span class="token punctuation">)</span>
    DB <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'DB'</span><span class="token punctuation">)</span>
    TABLE <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'TABLE'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> cls<span class="token punctuation">(</span>HOST<span class="token punctuation">,</span>PORT<span class="token punctuation">,</span>USER<span class="token punctuation">,</span>PWD<span class="token punctuation">,</span>DB<span class="token punctuation">,</span>TABLE<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    爬虫刚启动时执行一次
    """</span>
    self<span class="token punctuation">.</span>client <span class="token operator">=</span> MongoClient<span class="token punctuation">(</span><span class="token string">'mongodb://%s:%s@%s:%s'</span> <span class="token operator">%</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>user<span class="token punctuation">,</span>self<span class="token punctuation">.</span>pwd<span class="token punctuation">,</span>self<span class="token punctuation">.</span>host<span class="token punctuation">,</span>self<span class="token punctuation">.</span>port<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    爬虫关闭时执行一次
    """</span>
    self<span class="token punctuation">.</span>client<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

```

```
<span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 操作并进行持久化</span>

```


        self<span class="token punctuation">.</span>client<span class="token punctuation">[</span>self<span class="token punctuation">.</span>db<span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>table<span class="token punctuation">]</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>

<p><a target="_blank" rel="noopener" href="https://docs.scrapy.org/en/latest/topics/item-pipeline.html">https://docs.scrapy.org/en/latest/topics/item-pipeline.html</a></p>
<h3 id="九-Dowloader-Middeware"><a href="#九-Dowloader-Middeware" class="headerlink" title="九 Dowloader Middeware"></a>九 Dowloader Middeware</h3><pre class="language-python" data-language="python"><code class="language-python">下载中间件的用途
    <span class="token number">1</span>、在process——request内，自定义下载，不用scrapy的下载
    <span class="token number">2</span>、对请求进行二次加工，比如
        设置请求头
        设置cookie
        添加代理
            scrapy自带的代理组件：
                <span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>downloadermiddlewares<span class="token punctuation">.</span>httpproxy <span class="token keyword">import</span> HttpProxyMiddleware
                <span class="token keyword">from</span> urllib<span class="token punctuation">.</span>request <span class="token keyword">import</span> getproxies
<span class="token keyword">class</span> <span class="token class-name">DownMiddleware1</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        请求需要被下载时，经过所有下载器中间件的process_request调用
        :param request: 
        :param spider: 
        :return:  
            None,继续后续中间件去下载；
            Response对象，停止process_request的执行，开始执行process_response
            Request对象，停止中间件的执行，将Request重新调度器
            raise IgnoreRequest异常，停止process_request的执行，开始执行process_exception
        """</span>
        <span class="token keyword">pass</span>



```
<span class="token keyword">def</span> <span class="token function">process_response</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    spider处理完成，返回时调用
    :param response:
    :param result:
    :param spider:
    :return: 
        Response 对象：转交给其他中间件process_response
        Request 对象：停止中间件，request会被重新调度下载
        raise IgnoreRequest 异常：调用Request.errback
    """</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'response1'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> response

<span class="token keyword">def</span> <span class="token function">process_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    当下载处理器(download handler)或 process_request() (下载中间件)抛出异常
    :param response:
    :param exception:
    :param spider:
    :return: 
        None：继续交给后续中间件处理异常；
        Response对象：停止后续process_exception方法
        Request对象：停止中间件，request将会被重新调用下载
    """</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>
<span class="token comment">#1、与middlewares.py同级目录下新建proxy_handle.py</span>
<span class="token keyword">import</span> requests

<span class="token keyword">def</span> <span class="token function">get_proxy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"http://127.0.0.1:5010/get/"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text

<span class="token keyword">def</span> <span class="token function">delete_proxy</span><span class="token punctuation">(</span>proxy<span class="token punctuation">)</span><span class="token punctuation">:</span>
    requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"http://127.0.0.1:5010/delete/?proxy={}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>proxy<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    

<span class="token comment">#2、middlewares.py</span>
<span class="token keyword">from</span> Amazon<span class="token punctuation">.</span>proxy_handle <span class="token keyword">import</span> get_proxy<span class="token punctuation">,</span>delete_proxy

<span class="token keyword">class</span> <span class="token class-name">DownMiddleware1</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        请求需要被下载时，经过所有下载器中间件的process_request调用
        :param request:
        :param spider:
        :return:
            None,继续后续中间件去下载；
            Response对象，停止process_request的执行，开始执行process_response
            Request对象，停止中间件的执行，将Request重新调度器
            raise IgnoreRequest异常，停止process_request的执行，开始执行process_exception
        """</span>
        proxy<span class="token operator">=</span><span class="token string">"http://"</span> <span class="token operator">+</span> get_proxy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'download_timeout'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">20</span>
        request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">"proxy"</span><span class="token punctuation">]</span> <span class="token operator">=</span> proxy
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'为%s 添加代理%s '</span> <span class="token operator">%</span> <span class="token punctuation">(</span>request<span class="token punctuation">.</span>url<span class="token punctuation">,</span> proxy<span class="token punctuation">)</span><span class="token punctuation">,</span>end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'元数据为'</span><span class="token punctuation">,</span>request<span class="token punctuation">.</span>meta<span class="token punctuation">)</span>

```
<span class="token keyword">def</span> <span class="token function">process_response</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    spider处理完成，返回时调用
    :param response:
    :param result:
    :param spider:
    :return:
        Response 对象：转交给其他中间件process_response
        Request 对象：停止中间件，request会被重新调度下载
        raise IgnoreRequest 异常：调用Request.errback
    """</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'返回状态吗'</span><span class="token punctuation">,</span>response<span class="token punctuation">.</span>status<span class="token punctuation">)</span>
    <span class="token keyword">return</span> response

```

```
<span class="token keyword">def</span> <span class="token function">process_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    当下载处理器(download handler)或 process_request() (下载中间件)抛出异常
    :param response:
    :param exception:
    :param spider:
    :return:
        None：继续交给后续中间件处理异常；
        Response对象：停止后续process_exception方法
        Request对象：停止中间件，request将会被重新调用下载
    """</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'代理%s，访问%s出现异常:%s'</span> <span class="token operator">%</span><span class="token punctuation">(</span>request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'proxy'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>request<span class="token punctuation">.</span>url<span class="token punctuation">,</span>exception<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">import</span> time
    time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
    delete_proxy<span class="token punctuation">(</span>request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'proxy'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"//"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'proxy'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'http://'</span><span class="token operator">+</span>get_proxy<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> request</code></pre>

<h3 id="十-Spider-Middleware"><a href="#十-Spider-Middleware" class="headerlink" title="十 Spider Middleware"></a>十 Spider Middleware</h3><p><strong>1、爬虫中间件方法介绍</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> signals

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Not all methods need to be defined. If a method is not defined,</span>
    <span class="token comment"># scrapy acts as if the spider middleware does not modify the</span>
    <span class="token comment"># passed objects.</span>

    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># This method is used by Scrapy to create your spiders.</span>
        s <span class="token operator">=</span> cls<span class="token punctuation">(</span><span class="token punctuation">)</span>
        crawler<span class="token punctuation">.</span>signals<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>s<span class="token punctuation">.</span>spider_opened<span class="token punctuation">,</span> signal<span class="token operator">=</span>signals<span class="token punctuation">.</span>spider_opened<span class="token punctuation">)</span> <span class="token comment">#当前爬虫执行时触发spider_opened</span>
        <span class="token keyword">return</span> s

```
<span class="token keyword">def</span> <span class="token function">spider_opened</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># spider.logger.info('我是egon派来的爬虫1: %s' % spider.name)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'我是egon派来的爬虫1: %s'</span> <span class="token operator">%</span> spider<span class="token punctuation">.</span>name<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">process_start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> start_requests<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Called with the start requests of the spider, and works</span>
    <span class="token comment"># similarly to the process_spider_output() method, except</span>
    <span class="token comment"># that it doesn’t have a response associated.</span>

    <span class="token comment"># Must return only requests (not items).</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start_requests1'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> r <span class="token keyword">in</span> start_requests<span class="token punctuation">:</span>
        <span class="token keyword">yield</span> r

<span class="token keyword">def</span> <span class="token function">process_spider_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Called for each response that goes through the spider</span>
    <span class="token comment"># middleware and into the spider.</span>
    <span class="token comment"># 每个response经过爬虫中间件进入spider时调用</span>

    <span class="token comment"># 返回值：Should return None or raise an exception.</span>
    <span class="token comment">#1、None: 继续执行其他中间件的process_spider_input</span>
    <span class="token comment">#2、抛出异常：</span>
    <span class="token comment"># 一旦抛出异常则不再执行其他中间件的process_spider_input</span>
    <span class="token comment"># 并且触发request绑定的errback</span>
    <span class="token comment"># errback的返回值倒着传给中间件的process_spider_output</span>
    <span class="token comment"># 如果未找到errback，则倒着执行中间件的process_spider_exception</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input1"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">def</span> <span class="token function">process_spider_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> result<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Called with the results returned from the Spider, after</span>
    <span class="token comment"># it has processed the response.</span>

    <span class="token comment"># Must return an iterable of Request, dict or Item objects.</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output1'</span><span class="token punctuation">)</span>

    <span class="token comment"># 用yield返回多次，与return返回一次是一个道理</span>
    <span class="token comment"># 如果生成器掌握不好（函数内有yield执行函数得到的是生成器而并不会立刻执行），生成器的形式会容易误导你对中间件执行顺序的理解</span>
    <span class="token comment"># for i in result:</span>
    <span class="token comment">#     yield i</span>
    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">process_spider_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Called when a spider or process_spider_input() method</span>
    <span class="token comment"># (from other spider middleware) raises an exception.</span>

    <span class="token comment"># Should return either None or an iterable of Response, dict</span>
    <span class="token comment"># or Item objects.</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'exception1'</span><span class="token punctuation">)</span></code></pre>

<p><strong>2、当前爬虫启动时以及初始请求产生时</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#步骤一：</span>
<span class="token triple-quoted-string string">'''
打开注释：
SPIDER_MIDDLEWARES = {
   'Baidu.middlewares.SpiderMiddleware1': 200,
   'Baidu.middlewares.SpiderMiddleware2': 300,
   'Baidu.middlewares.SpiderMiddleware3': 400,
}

'''</span>

<span class="token comment">#步骤二：middlewares.py</span>
<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> signals

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware1</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
        s <span class="token operator">=</span> cls<span class="token punctuation">(</span><span class="token punctuation">)</span>
        crawler<span class="token punctuation">.</span>signals<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>s<span class="token punctuation">.</span>spider_opened<span class="token punctuation">,</span> signal<span class="token operator">=</span>signals<span class="token punctuation">.</span>spider_opened<span class="token punctuation">)</span> <span class="token comment">#当前爬虫执行时触发spider_opened</span>
        <span class="token keyword">return</span> s

```
<span class="token keyword">def</span> <span class="token function">spider_opened</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'我是egon派来的爬虫1: %s'</span> <span class="token operator">%</span> spider<span class="token punctuation">.</span>name<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">process_start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> start_requests<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Must return only requests (not items).</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start_requests1'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> r <span class="token keyword">in</span> start_requests<span class="token punctuation">:</span>
        <span class="token keyword">yield</span> r

```

        
        
<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware2</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
        s <span class="token operator">=</span> cls<span class="token punctuation">(</span><span class="token punctuation">)</span>
        crawler<span class="token punctuation">.</span>signals<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>s<span class="token punctuation">.</span>spider_opened<span class="token punctuation">,</span> signal<span class="token operator">=</span>signals<span class="token punctuation">.</span>spider_opened<span class="token punctuation">)</span>  <span class="token comment"># 当前爬虫执行时触发spider_opened</span>
        <span class="token keyword">return</span> s

```
<span class="token keyword">def</span> <span class="token function">spider_opened</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'我是egon派来的爬虫2: %s'</span> <span class="token operator">%</span> spider<span class="token punctuation">.</span>name<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">process_start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> start_requests<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start_requests2'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> r <span class="token keyword">in</span> start_requests<span class="token punctuation">:</span>
        <span class="token keyword">yield</span> r

```

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware3</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
        s <span class="token operator">=</span> cls<span class="token punctuation">(</span><span class="token punctuation">)</span>
        crawler<span class="token punctuation">.</span>signals<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>s<span class="token punctuation">.</span>spider_opened<span class="token punctuation">,</span> signal<span class="token operator">=</span>signals<span class="token punctuation">.</span>spider_opened<span class="token punctuation">)</span>  <span class="token comment"># 当前爬虫执行时触发spider_opened</span>
        <span class="token keyword">return</span> s

```
<span class="token keyword">def</span> <span class="token function">spider_opened</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'我是egon派来的爬虫3: %s'</span> <span class="token operator">%</span> spider<span class="token punctuation">.</span>name<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">process_start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> start_requests<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'start_requests3'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> r <span class="token keyword">in</span> start_requests<span class="token punctuation">:</span>
        <span class="token keyword">yield</span> r

```

<span class="token comment">#步骤三：分析运行结果</span>
<span class="token comment">#1、启动爬虫时则立刻执行：</span>

我是egon派来的爬虫<span class="token number">1</span><span class="token punctuation">:</span> baidu
我是egon派来的爬虫<span class="token number">2</span><span class="token punctuation">:</span> baidu
我是egon派来的爬虫<span class="token number">3</span><span class="token punctuation">:</span> baidu

<span class="token comment">#2、然后产生一个初始的request请求，依次经过爬虫中间件1,2,3：</span>
start_requests1
start_requests2
start_requests3</code></pre>

<p><strong>3、process_spider_input返回None时</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#步骤一：打开注释：</span>
SPIDER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">'Baidu.middlewares.SpiderMiddleware1'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">,</span>
   <span class="token string">'Baidu.middlewares.SpiderMiddleware2'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
   <span class="token string">'Baidu.middlewares.SpiderMiddleware3'</span><span class="token punctuation">:</span> <span class="token number">400</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

<span class="token string">''</span>'

<span class="token comment">#步骤二：middlewares.py</span>
<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> signals

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware1</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

```
<span class="token keyword">def</span> <span class="token function">process_spider_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input1"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">process_spider_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> result<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output1'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">process_spider_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'exception1'</span><span class="token punctuation">)</span>

```

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware2</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

```
<span class="token keyword">def</span> <span class="token function">process_spider_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input2"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">def</span> <span class="token function">process_spider_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> result<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output2'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">process_spider_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'exception2'</span><span class="token punctuation">)</span>

```

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware3</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

```
<span class="token keyword">def</span> <span class="token function">process_spider_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input3"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">def</span> <span class="token function">process_spider_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> result<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output3'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">process_spider_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'exception3'</span><span class="token punctuation">)</span>

```

<span class="token comment">#步骤三：运行结果分析</span>

<span class="token comment">#1、返回response时，依次经过爬虫中间件1,2,3</span>
input1
input2
input3

<span class="token comment">#2、spider处理完毕后，依次经过爬虫中间件3,2,1</span>
output3
output2
output1</code></pre>

<p><strong>4、process_spider_input抛出异常时</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#步骤一：</span>
<span class="token triple-quoted-string string">'''
打开注释：
SPIDER_MIDDLEWARES = {
   'Baidu.middlewares.SpiderMiddleware1': 200,
   'Baidu.middlewares.SpiderMiddleware2': 300,
   'Baidu.middlewares.SpiderMiddleware3': 400,
}

'''</span>

<span class="token comment">#步骤二：middlewares.py</span>

<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> signals

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware1</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

```
<span class="token keyword">def</span> <span class="token function">process_spider_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input1"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">process_spider_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> result<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output1'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">process_spider_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'exception1'</span><span class="token punctuation">)</span>

```

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware2</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

```
<span class="token keyword">def</span> <span class="token function">process_spider_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input2"</span><span class="token punctuation">)</span>
    <span class="token keyword">raise</span> Type

<span class="token keyword">def</span> <span class="token function">process_spider_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> result<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output2'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">process_spider_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'exception2'</span><span class="token punctuation">)</span>

```

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware3</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

```
<span class="token keyword">def</span> <span class="token function">process_spider_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input3"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">def</span> <span class="token function">process_spider_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> result<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output3'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">process_spider_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'exception3'</span><span class="token punctuation">)</span>

```

        

<span class="token comment">#运行结果        </span>
input1
input2
exception3
exception2
exception1

<span class="token comment">#分析：</span>
<span class="token comment">#1、当response经过中间件1的 process_spider_input返回None，继续交给中间件2的process_spider_input</span>
<span class="token comment">#2、中间件2的process_spider_input抛出异常，则直接跳过后续的process_spider_input，将异常信息传递给Spiders里该请求的errback</span>
<span class="token comment">#3、没有找到errback，则该response既没有被Spiders正常的callback执行，也没有被errback执行，即Spiders啥事也没有干，那么开始倒着执行process_spider_exception</span>
<span class="token comment">#4、如果process_spider_exception返回None，代表该方法推卸掉责任，并没处理异常，而是直接交给下一个process_spider_exception，全都返回None，则异常最终交给Engine抛出</span></code></pre>

<p><strong>5、指定errback</strong></p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#步骤一：spider.py</span>
<span class="token keyword">import</span> scrapy



<span class="token keyword">class</span> <span class="token class-name">BaiduSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'baidu'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'www.baidu.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.baidu.com/'</span><span class="token punctuation">]</span>

```
<span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span><span class="token string">'http://www.baidu.com/'</span><span class="token punctuation">,</span>
                         callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">,</span>
                         errback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_err<span class="token punctuation">,</span>
                         <span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">pass</span>

<span class="token keyword">def</span> <span class="token function">parse_err</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>res<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#res 为异常信息，异常已经被该函数处理了，因此不会再抛给因此，于是开始走process_spider_output</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token comment">#提取异常信息中有用的数据以可迭代对象的形式存放于管道中，等待被process_spider_output取走</span>

```



<span class="token comment">#步骤二：</span>
<span class="token triple-quoted-string string">'''
打开注释：
SPIDER_MIDDLEWARES = {
   'Baidu.middlewares.SpiderMiddleware1': 200,
   'Baidu.middlewares.SpiderMiddleware2': 300,
   'Baidu.middlewares.SpiderMiddleware3': 400,
}

'''</span>

<span class="token comment">#步骤三：middlewares.py</span>

<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> signals

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware1</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

```
<span class="token keyword">def</span> <span class="token function">process_spider_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input1"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">process_spider_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> result<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output1'</span><span class="token punctuation">,</span><span class="token builtin">list</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">process_spider_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'exception1'</span><span class="token punctuation">)</span>

```

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware2</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

```
<span class="token keyword">def</span> <span class="token function">process_spider_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input2"</span><span class="token punctuation">)</span>
    <span class="token keyword">raise</span> TypeError<span class="token punctuation">(</span><span class="token string">'input2 抛出异常'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">process_spider_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> result<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output2'</span><span class="token punctuation">,</span><span class="token builtin">list</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">process_spider_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'exception2'</span><span class="token punctuation">)</span>

```

<span class="token keyword">class</span> <span class="token class-name">SpiderMiddleware3</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

```
<span class="token keyword">def</span> <span class="token function">process_spider_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input3"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">def</span> <span class="token function">process_spider_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> result<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output3'</span><span class="token punctuation">,</span><span class="token builtin">list</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">process_spider_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'exception3'</span><span class="token punctuation">)</span>

```



<span class="token comment">#步骤四：运行结果分析</span>
input1
input2
output3 <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span> <span class="token comment">#parse_err的返回值放入管道中，只能被取走一次，在output3的方法内可以根据异常信息封装一个新的request请求</span>
output2 <span class="token punctuation">[</span><span class="token punctuation">]</span>
output1 <span class="token punctuation">[</span><span class="token punctuation">]</span></code></pre>

<h3 id="十一-自定义扩展"><a href="#十一-自定义扩展" class="headerlink" title="十一 自定义扩展"></a>十一 自定义扩展</h3><pre class="language-python" data-language="python"><code class="language-python">自定义扩展（与django的信号类似）
    <span class="token number">1</span>、django的信号是django是预留的扩展，信号一旦被触发，相应的功能就会执行
    <span class="token number">2</span>、scrapy自定义扩展的好处是可以在任意我们想要的位置添加功能，而其他组件中提供的功能只能在规定的位置执行
<span class="token comment">#1、在与settings同级目录下新建一个文件，文件名可以为extentions.py,内容如下</span>
<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> signals



<span class="token keyword">class</span> <span class="token class-name">MyExtension</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>value <span class="token operator">=</span> value

```
<span class="token decorator annotation punctuation">@classmethod</span>
<span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
    val <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>getint<span class="token punctuation">(</span><span class="token string">'MMMM'</span><span class="token punctuation">)</span>
    obj <span class="token operator">=</span> cls<span class="token punctuation">(</span>val<span class="token punctuation">)</span>

    crawler<span class="token punctuation">.</span>signals<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>obj<span class="token punctuation">.</span>spider_opened<span class="token punctuation">,</span> signal<span class="token operator">=</span>signals<span class="token punctuation">.</span>spider_opened<span class="token punctuation">)</span>
    crawler<span class="token punctuation">.</span>signals<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>obj<span class="token punctuation">.</span>spider_closed<span class="token punctuation">,</span> signal<span class="token operator">=</span>signals<span class="token punctuation">.</span>spider_closed<span class="token punctuation">)</span>

    <span class="token keyword">return</span> obj

<span class="token keyword">def</span> <span class="token function">spider_opened</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'=============&gt;open'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">spider_closed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'=============&gt;close'</span><span class="token punctuation">)</span>

```

<span class="token comment">#2、配置生效</span>
EXTENSIONS <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"Amazon.extentions.MyExtension"</span><span class="token punctuation">:</span><span class="token number">200</span>
<span class="token punctuation">}</span></code></pre>

<h3 id="十二-settings-py"><a href="#十二-settings-py" class="headerlink" title="十二 settings.py"></a>十二 settings.py</h3><pre class="language-python" data-language="python"><code class="language-python"><span class="token comment">#==&gt;第一部分：基本配置&lt;===</span>
<span class="token comment">#1、项目名称，默认的USER_AGENT由它来构成，也作为日志记录的日志名</span>
BOT_NAME <span class="token operator">=</span> <span class="token string">'Amazon'</span>

<span class="token comment">#2、爬虫应用路径</span>
SPIDER_MODULES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Amazon.spiders'</span><span class="token punctuation">]</span>
NEWSPIDER_MODULE <span class="token operator">=</span> <span class="token string">'Amazon.spiders'</span>

<span class="token comment">#3、客户端User-Agent请求头</span>
<span class="token comment">#USER_AGENT = 'Amazon (+http://www.yourdomain.com)'</span>

<span class="token comment">#4、是否遵循爬虫协议</span>
<span class="token comment"># Obey robots.txt rules</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>

<span class="token comment">#5、是否支持cookie，cookiejar进行操作cookie，默认开启</span>
<span class="token comment">#COOKIES_ENABLED = False</span>

<span class="token comment">#6、Telnet用于查看当前爬虫的信息，操作爬虫等...使用telnet ip port ，然后通过命令操作</span>
<span class="token comment">#TELNETCONSOLE_ENABLED = False</span>
<span class="token comment">#TELNETCONSOLE_HOST = '127.0.0.1'</span>
<span class="token comment">#TELNETCONSOLE_PORT = [6023,]</span>

<span class="token comment">#7、Scrapy发送HTTP请求默认使用的请求头</span>
<span class="token comment">#DEFAULT_REQUEST_HEADERS = {</span>
<span class="token comment">#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',</span>
<span class="token comment">#   'Accept-Language': 'en',</span>
<span class="token comment">#}</span>



<span class="token comment">#===&gt;第二部分：并发与延迟&lt;===</span>
<span class="token comment">#1、下载器总共最大处理的并发请求数,默认值16</span>
<span class="token comment">#CONCURRENT_REQUESTS = 32</span>

<span class="token comment">#2、每个域名能够被执行的最大并发请求数目，默认值8</span>
<span class="token comment">#CONCURRENT_REQUESTS_PER_DOMAIN = 16</span>

<span class="token comment">#3、能够被单个IP处理的并发请求数，默认值0，代表无限制，需要注意两点</span>
<span class="token comment">#I、如果不为零，那CONCURRENT_REQUESTS_PER_DOMAIN将被忽略，即并发数的限制是按照每个IP来计算，而不是每个域名</span>
<span class="token comment">#II、该设置也影响DOWNLOAD_DELAY，如果该值不为零，那么DOWNLOAD_DELAY下载延迟是限制每个IP而不是每个域</span>
<span class="token comment">#CONCURRENT_REQUESTS_PER_IP = 16</span>

<span class="token comment">#4、如果没有开启智能限速，这个值就代表一个规定死的值，代表对同一网址延迟请求的秒数</span>
<span class="token comment">#DOWNLOAD_DELAY = 3</span>

<span class="token comment">#===&gt;第三部分：智能限速/自动节流：AutoThrottle extension&lt;===</span>
<span class="token comment">#一：介绍</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>throttle <span class="token keyword">import</span> AutoThrottle <span class="token comment">#http://scrapy.readthedocs.io/en/latest/topics/autothrottle.html#topics-autothrottle</span>
设置目标：
<span class="token number">1</span>、比使用默认的下载延迟对站点更好
<span class="token number">2</span>、自动调整scrapy到最佳的爬取速度，所以用户无需自己调整下载延迟到最佳状态。用户只需要定义允许最大并发的请求，剩下的事情由该扩展组件自动完成

<span class="token comment">#二：如何实现？</span>
在Scrapy中，下载延迟是通过计算建立TCP连接到接收到HTTP包头<span class="token punctuation">(</span>header<span class="token punctuation">)</span>之间的时间来测量的。
注意，由于Scrapy可能在忙着处理spider的回调函数或者无法下载，因此在合作的多任务环境下准确测量这些延迟是十分苦难的。 不过，这些延迟仍然是对Scrapy<span class="token punctuation">(</span>甚至是服务器<span class="token punctuation">)</span>繁忙程度的合理测量，而这扩展就是以此为前提进行编写的。

<span class="token comment">#三：限速算法</span>
自动限速算法基于以下规则调整下载延迟
<span class="token comment">#1、spiders开始时的下载延迟是基于AUTOTHROTTLE_START_DELAY的值</span>
<span class="token comment">#2、当收到一个response，对目标站点的下载延迟=收到响应的延迟时间/AUTOTHROTTLE_TARGET_CONCURRENCY</span>
<span class="token comment">#3、下一次请求的下载延迟就被设置成：对目标站点下载延迟时间和过去的下载延迟时间的平均值</span>
<span class="token comment">#4、没有达到200个response则不允许降低延迟</span>
<span class="token comment">#5、下载延迟不能变的比DOWNLOAD_DELAY更低或者比AUTOTHROTTLE_MAX_DELAY更高</span>

<span class="token comment">#四：配置使用</span>
<span class="token comment">#开启True，默认False</span>
AUTOTHROTTLE_ENABLED <span class="token operator">=</span> <span class="token boolean">True</span>
<span class="token comment">#起始的延迟</span>
AUTOTHROTTLE_START_DELAY <span class="token operator">=</span> <span class="token number">5</span>
<span class="token comment">#最小延迟</span>
DOWNLOAD_DELAY <span class="token operator">=</span> <span class="token number">3</span>
<span class="token comment">#最大延迟</span>
AUTOTHROTTLE_MAX_DELAY <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment">#每秒并发请求数的平均值，不能高于 CONCURRENT_REQUESTS_PER_DOMAIN或CONCURRENT_REQUESTS_PER_IP，调高了则吞吐量增大强奸目标站点，调低了则对目标站点更加”礼貌“</span>
<span class="token comment">#每个特定的时间点，scrapy并发请求的数目都可能高于或低于该值，这是爬虫视图达到的建议值而不是硬限制</span>
AUTOTHROTTLE_TARGET_CONCURRENCY <span class="token operator">=</span> <span class="token number">16.0</span>
<span class="token comment">#调试</span>
AUTOTHROTTLE_DEBUG <span class="token operator">=</span> <span class="token boolean">True</span>
CONCURRENT_REQUESTS_PER_DOMAIN <span class="token operator">=</span> <span class="token number">16</span>
CONCURRENT_REQUESTS_PER_IP <span class="token operator">=</span> <span class="token number">16</span>



<span class="token comment">#===&gt;第四部分：爬取深度与爬取方式&lt;===</span>
<span class="token comment">#1、爬虫允许的最大深度，可以通过meta查看当前深度；0表示无深度</span>
<span class="token comment"># DEPTH_LIMIT = 3</span>

<span class="token comment">#2、爬取时，0表示深度优先Lifo(默认)；1表示广度优先FiFo</span>

<span class="token comment"># 后进先出，深度优先</span>
<span class="token comment"># DEPTH_PRIORITY = 0</span>
<span class="token comment"># SCHEDULER_DISK_QUEUE = 'scrapy.squeue.PickleLifoDiskQueue'</span>
<span class="token comment"># SCHEDULER_MEMORY_QUEUE = 'scrapy.squeue.LifoMemoryQueue'</span>
<span class="token comment"># 先进先出，广度优先</span>

<span class="token comment"># DEPTH_PRIORITY = 1</span>
<span class="token comment"># SCHEDULER_DISK_QUEUE = 'scrapy.squeue.PickleFifoDiskQueue'</span>
<span class="token comment"># SCHEDULER_MEMORY_QUEUE = 'scrapy.squeue.FifoMemoryQueue'</span>

<span class="token comment">#3、调度器队列</span>
<span class="token comment"># SCHEDULER = 'scrapy.core.scheduler.Scheduler'</span>
<span class="token comment"># from scrapy.core.scheduler import Scheduler</span>

<span class="token comment">#4、访问URL去重</span>
<span class="token comment"># DUPEFILTER_CLASS = 'step8_king.duplication.RepeatUrl'</span>



<span class="token comment">#===&gt;第五部分：中间件、Pipelines、扩展&lt;===</span>
<span class="token comment">#1、Enable or disable spider middlewares</span>
<span class="token comment"># See http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html</span>
<span class="token comment">#SPIDER_MIDDLEWARES = {</span>
<span class="token comment">#    'Amazon.middlewares.AmazonSpiderMiddleware': 543,</span>
<span class="token comment">#}</span>

<span class="token comment">#2、Enable or disable downloader middlewares</span>
<span class="token comment"># See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html</span>
DOWNLOADER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token comment"># 'Amazon.middlewares.DownMiddleware1': 543,</span>
<span class="token punctuation">}</span>

<span class="token comment">#3、Enable or disable extensions</span>
<span class="token comment"># See http://scrapy.readthedocs.org/en/latest/topics/extensions.html</span>
<span class="token comment">#EXTENSIONS = {</span>
<span class="token comment">#    'scrapy.extensions.telnet.TelnetConsole': None,</span>
<span class="token comment">#}</span>

<span class="token comment">#4、Configure item pipelines</span>
<span class="token comment"># See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token comment"># 'Amazon.pipelines.CustomPipeline': 200,</span>
<span class="token punctuation">}</span>



<span class="token comment">#===&gt;第六部分：缓存&lt;===</span>
<span class="token triple-quoted-string string">"""

1. 启用缓存
   目的用于将已经发送的请求或相应缓存下来，以便以后使用

   from scrapy.downloadermiddlewares.httpcache import HttpCacheMiddleware
   from scrapy.extensions.httpcache import DummyPolicy
   from scrapy.extensions.httpcache import FilesystemCacheStorage
   """</span>
   <span class="token comment"># 是否启用缓存策略</span>
   <span class="token comment"># HTTPCACHE_ENABLED = True</span>

<span class="token comment"># 缓存策略：所有请求均缓存，下次在请求直接访问原来的缓存即可</span>
<span class="token comment"># HTTPCACHE_POLICY = "scrapy.extensions.httpcache.DummyPolicy"</span>
<span class="token comment"># 缓存策略：根据Http响应头：Cache-Control、Last-Modified 等进行缓存的策略</span>
<span class="token comment"># HTTPCACHE_POLICY = "scrapy.extensions.httpcache.RFC2616Policy"</span>

<span class="token comment"># 缓存超时时间</span>
<span class="token comment"># HTTPCACHE_EXPIRATION_SECS = 0</span>

<span class="token comment"># 缓存保存路径</span>
<span class="token comment"># HTTPCACHE_DIR = 'httpcache'</span>

<span class="token comment"># 缓存忽略的Http状态码</span>
<span class="token comment"># HTTPCACHE_IGNORE_HTTP_CODES = []</span>

<span class="token comment"># 缓存存储的插件</span>
<span class="token comment"># HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'</span>

<span class="token comment">#===&gt;第七部分：线程池&lt;===</span>
REACTOR_THREADPOOL_MAXSIZE <span class="token operator">=</span> <span class="token number">10</span>

<span class="token comment">#Default: 10</span>
<span class="token comment">#scrapy基于twisted异步IO框架，downloader是多线程的，线程数是Twisted线程池的默认大小(The maximum limit for Twisted Reactor thread pool size.)</span>

<span class="token comment">#关于twisted线程池：</span>
http<span class="token punctuation">:</span><span class="token operator">//</span>twistedmatrix<span class="token punctuation">.</span>com<span class="token operator">/</span>documents<span class="token operator">/</span><span class="token number">10.1</span><span class="token number">.0</span><span class="token operator">/</span>core<span class="token operator">/</span>howto<span class="token operator">/</span>threading<span class="token punctuation">.</span>html

<span class="token comment">#线程池实现：twisted.python.threadpool.ThreadPool</span>
twisted调整线程池大小：
<span class="token keyword">from</span> twisted<span class="token punctuation">.</span>internet <span class="token keyword">import</span> reactor
reactor<span class="token punctuation">.</span>suggestThreadPoolSize<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span>

<span class="token comment">#scrapy相关源码：</span>
D<span class="token punctuation">:</span>\python3<span class="token punctuation">.</span><span class="token number">6</span>\Lib\site<span class="token operator">-</span>packages\scrapy\crawler<span class="token punctuation">.</span>py

<span class="token comment">#补充：</span>
windows下查看进程内线程数的工具：
    https<span class="token punctuation">:</span><span class="token operator">//</span>docs<span class="token punctuation">.</span>microsoft<span class="token punctuation">.</span>com<span class="token operator">/</span>zh<span class="token operator">-</span>cn<span class="token operator">/</span>sysinternals<span class="token operator">/</span>downloads<span class="token operator">/</span>pslist
    或
    https<span class="token punctuation">:</span><span class="token operator">//</span>pan<span class="token punctuation">.</span>baidu<span class="token punctuation">.</span>com<span class="token operator">/</span>s<span class="token operator">/</span>1jJ0pMaM
    

```
命令为：
pslist <span class="token operator">|</span>findstr python

```

linux下：top <span class="token operator">-</span>p 进程<span class="token builtin">id</span>

<span class="token comment">#===&gt;第八部分：其他默认配置参考&lt;===</span>
D<span class="token punctuation">:</span>\python3<span class="token punctuation">.</span><span class="token number">6</span>\Lib\site<span class="token operator">-</span>packages\scrapy\settings\default_settings<span class="token punctuation">.</span>py</code></pre>

<h3 id="十三-自定制命令"><a href="#十三-自定制命令" class="headerlink" title="十三 自定制命令"></a>十三 自定制命令</h3><ul>
<li><p>在spiders同级创建任意目录，如：commands</p>
</li>
<li><p>在其中创建 crawlall.py 文件 （此处文件名就是自定义的命令）</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>commands <span class="token keyword">import</span> ScrapyCommand
  <span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>project <span class="token keyword">import</span> get_project_settings
  
  
  <span class="token keyword">class</span> <span class="token class-name">Command</span><span class="token punctuation">(</span>ScrapyCommand<span class="token punctuation">)</span><span class="token punctuation">:</span>
  
      requires_project <span class="token operator">=</span> <span class="token boolean">True</span>
  
      <span class="token keyword">def</span> <span class="token function">syntax</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
          <span class="token keyword">return</span> <span class="token string">'[options]'</span>
  
      <span class="token keyword">def</span> <span class="token function">short_desc</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
          <span class="token keyword">return</span> <span class="token string">'Runs all of the spiders'</span>
  
      <span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> args<span class="token punctuation">,</span> opts<span class="token punctuation">)</span><span class="token punctuation">:</span>
          spider_list <span class="token operator">=</span> self<span class="token punctuation">.</span>crawler_process<span class="token punctuation">.</span>spiders<span class="token punctuation">.</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
          <span class="token keyword">for</span> name <span class="token keyword">in</span> spider_list<span class="token punctuation">:</span>
              self<span class="token punctuation">.</span>crawler_process<span class="token punctuation">.</span>crawl<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token operator">**</span>opts<span class="token punctuation">.</span>__dict__<span class="token punctuation">)</span>
          self<span class="token punctuation">.</span>crawler_process<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
</li>
<li><p>在settings.py 中添加配置 COMMANDS_MODULE = ‘项目名称.目录名称’</p>
</li>
<li><p>在项目目录执行命令：scrapy crawlall</p>
</li>
</ul>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">祈安</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://example.com/2021/10/09/Scrapy/">http://example.com/2021/10/09/Scrapy/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">祈安</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E7%88%AC%E8%99%AB-Scrapy/">
                                    <span class="chip bg-color">爬虫-Scrapy</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: '',
        clientSecret: '',
        repo: '',
        owner: '',
        admin: null,
        id: '2021-10-09T19-23-21',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2021/10/10/Beautifulsoup4/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/2.jpg" class="responsive-img" alt="爬虫-Beautifulsoup4">
                        
                        <span class="card-title">爬虫-Beautifulsoup4</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Beautiful Soup
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-10-10
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Beautifulsoup4/" class="post-category">
                                    Beautifulsoup4
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E7%88%AC%E8%99%AB-Beautifulsoup4/">
                        <span class="chip bg-color">爬虫-Beautifulsoup4</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/10/08/SQLAlchemy/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/11.jpg" class="responsive-img" alt="FLask-SQLAlchemy">
                        
                        <span class="card-title">FLask-SQLAlchemy</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-10-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Flask/" class="post-category">
                                    Flask
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/FLask-SQLAlchemy/">
                        <span class="chip bg-color">FLask-SQLAlchemy</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('100')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'CODE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 且听风吟<br />'
            + '文章作者: 祈安<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFunction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>

    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="tencent"
                   type="playlist"
                   id="4628814494"
                   fixed='true'
                   autoplay='true'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2020-2022</span>
            
            <span id="year">2020</span>
            <a href="/about" target="_blank">祈安</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">103.8k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:jiangychao@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=913126194" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 913126194" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true,"react":{"opacity":0.7}}});</script></body>

</html>
